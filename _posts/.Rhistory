ungroup()
# 5.3 LinkedIn ----
linkedin_clean = linkedin %>%
drop_na() %>%
# get names correctly
set_names(names(.) %>% str_replace_all("\\/ ","") %>%
str_replace_all(" - ", "_") %>%
str_replace_all(" ","_") %>%
str_to_lower()) %>%
# change date format
mutate(date = date %>% ymd()) %>%
# add channel
mutate(channel = "LinkedIn") %>%
# add operation
mutate(operation = case_when(
landing_page_url %>% str_detect("onboardfromhome") ~ "Onboard from Home",
TRUE ~ "Other"
)) %>%
# select only proper columns
select(channel, operation, date, everything()) %>%
select(-c("campaign", "landing_page_url")) %>%
# summarize by channel, operation, date
group_by(channel, operation, date) %>%
summarize_all(sum) %>%
ungroup()
# 5.4 Twitter ----
twitter_clean = twitter %>%
drop_na() %>%
# get names correctly
set_names(names(.) %>% str_replace_all("\\/ ","") %>%
str_replace_all(" - ", "_") %>%
str_replace_all(" ","_") %>%
str_to_lower()) %>%
# change date format
mutate(date = date %>% ymd()) %>%
# add channel
mutate(channel = "Twitter") %>%
# add operation
mutate(operation = case_when(
landing_page_url %>% str_detect("onboardfromhome") ~ "Onboard from Home",
TRUE ~ "Other"
)) %>%
# select only proper columns
select(channel, operation, date, everything()) %>%
select(-c("campaign", "landing_page_url")) %>%
# summarize by channel, operation, date
group_by(channel, operation, date) %>%
summarize_all(sum) %>%
ungroup()
# 5.5 Quora ----
quora_clean = quora %>%
drop_na() %>%
# get names correctly
set_names(names(.) %>% str_replace_all("\\/ ","") %>%
str_replace_all(" - ", "_") %>%
str_replace_all(" ","_") %>%
str_to_lower()) %>%
# change date format
mutate(date = date %>% ymd()) %>%
# add channel
mutate(channel = "Quora") %>%
# add operation
mutate(operation = case_when(
landing_page_url %>% str_detect("onboardfromhome") ~ "Onboard from Home",
TRUE ~ "Other"
)) %>%
# select only proper columns
select(channel, operation, date, everything()) %>%
select(-c("campaign", "landing_page_url")) %>%
# summarize by channel, operation, date
group_by(channel, operation, date) %>%
summarize_all(sum) %>%
ungroup()
# 5.6 CoinTelegraph ----
coin_telegraph_clean = coin_telegraph %>%
# remove first 3 rows
slice(-c(1,2,3)) %>%
# keep only first 3 columns
select(1:3) %>%
# set good names
set_names(c("date", "impressions", "cost")) %>%
# change data format
mutate(date = date %>% mdy()) %>%
# remove all NAs
drop_na() %>%
# add channel and operation
mutate(channel = "Coin Telegraph",
operation = case_when(
date > "2020-01-14" & date < "2020-04-30" ~ "Peace of Mind",
TRUE ~ "Onboard from Home"
)) %>%
# relocate
select(channel, everything())
# 5.5 Join Tables ----
# bind paid channels
paid_channels = display_clean %>%
bind_rows(linkedin_clean, twitter_clean, quora_clean, coin_telegraph_clean)
final_table = google_analytics_clean %>%
left_join(paid_channels, by = c("channel" = "channel", "operation" = "operation", "date" = "date")) %>%
mutate(clicks = case_when(
channel %>% str_detect("Coin Telegraph") ~ sessions,
TRUE ~ clicks,
)) %>%
drop_na() %>%
set_names(names(.) %>% str_trim())
View(final_table)
# Quality Score Tracker
# Author: Arben Kqiku
# Contact: arben@comtogether.com
# Version: 1.0.1
# *** FUNCTIONS -------------------------------------------------------------------------------
# 1) load google ads credentials ----------------------------------------------------------
load.credentials = function(google_auth_path){
if(!require(RAdwords)){
install.packages('RAdwords') # install package if not installed
}
# google ads credentials (you receive the client token from the authentification process)
# you cannot take the name of the variable and paste it, you need the actual string
client.id = '1085236241189-q4gst9bas3ar1v7igqhh6m7tsns4f049.apps.googleusercontent.com'
client.secret = 'kYTBc88HQDAryFrVSBP3NnSk'
developers.token = 'KYbpUwUGRwXdgHvQt8XjrA'
# Check if the google_auth RData file already exists, create if not
if(!file.exists(google_auth_path)) {
google_auth <- doAuth(save = FALSE)
# Save the auth credentials, to be used the auth from a file from now on
save(google_auth, file = google_auth_path)
}
# Load Google auth credentials / no need to assign it to a variable, otherwise it will be understood as character.
# Simply load it and the original variable that was used to load it will be used.
load(file = google_auth_path, envir=.GlobalEnv)
}
# 2) function that retrieves the data of the quality score  -------------------------------
get.quality.score = function(account.id){
# define a statement so that you can query data
get.metrics = c('CampaignName','AdGroupName','Criteria','Date',
'Impressions', 'HasQualityScore','QualityScore',
'CreativeQualityScore','PostClickQualityScore','SearchPredictedCtr')
get.report = 'KEYWORDS_PERFORMANCE_REPORT'
get.start = as.Date(start.date)
get.end = as.Date(end.date)
body = statement(select = get.metrics, report = get.report, start = get.start, end = get.end)
campaign.keywords = getData(clientCustomerId = account.id, google_auth = google_auth, statement = body,
transformation = TRUE, changeNames = TRUE)
return(campaign.keywords)
}
# 3) transform quality score in numbers ---------------------------------------------------
transform.in.numbers = function(){
quality.score.data$Adrelevance[quality.score.data$Adrelevance == "Below average"] = 0
quality.score.data$Landingpageexperience[quality.score.data$Landingpageexperience == "Below average"] = 0
quality.score.data$Expectedclickthroughrate[quality.score.data$Expectedclickthroughrate == "Below average"] = 0
quality.score.data$Adrelevance[quality.score.data$Adrelevance == "Average"] = 1
quality.score.data$Landingpageexperience[quality.score.data$Landingpageexperience == "Average"] = 1.75
quality.score.data$Expectedclickthroughrate[quality.score.data$Expectedclickthroughrate == "Average"] = 1.75
quality.score.data$Adrelevance[quality.score.data$Adrelevance == "Above average"] = 2
quality.score.data$Landingpageexperience[quality.score.data$Landingpageexperience == "Above average"] = 3.5
quality.score.data$Expectedclickthroughrate[quality.score.data$Expectedclickthroughrate == "Above average"] = 3.5
return(quality.score.data)
}
# 4) create table to accomodate data at the ad group level --------------------------------
create.accomodate.table.adgroups = function(){
table.to.accomodate = unique(quality.score.data[c("Account","Campaign", "Adgroup", "Day")])
table.to.accomodate$Impressions = 0
table.to.accomodate$Qualityscore = 0
table.to.accomodate$Adrelevance = 0
table.to.accomodate$Landingpageexperience = 0
table.to.accomodate$Expectedclickthroughrate = 0
return(table.to.accomodate)
}
# 5) create table to accomodate data at the campaign level ---------------------------------
create.accomodate.table.campaigns = function(){
table.to.accomodate = unique(quality.score.data[c("Account","Campaign", "Day")])
table.to.accomodate$Impressions = 0
table.to.accomodate$Qualityscore = 0
table.to.accomodate$Adrelevance = 0
table.to.accomodate$Landingpageexperience = 0
table.to.accomodate$Expectedclickthroughrate = 0
return(table.to.accomodate)
}
# 6) function that populated the table with quality score data at the keyword level-------
populate.table.keywords = function(table){
# change scale for landing page experience, expected CTR and ad relevance
table$Landingpageexperience = round(as.numeric(table$Landingpageexperience)/3.5*10, digits = 2)
table$Expectedclickthroughrate = round(as.numeric(table$Expectedclickthroughrate)/3.5*10, digits = 2)
table$Adrelevance = round(as.numeric(table$Adrelevance)/2*10, digits = 2)
return(table)
}
# 7) function that populated the table with quality score data at the ad group level-------
populate.table.adgroups = function(){
# length
lang = nrow(accomodate.table)
print("No. Iterations:")
print(lang)
# lang = 10000
for(i in 1:lang){
# test
# i = 30
print(i)
# get the data for one campaign, one ad group and one day in particular
current.data = quality.score.data %>% filter(Account == accomodate.table$Account[i],
Campaign == accomodate.table$Campaign[i],
Adgroup == accomodate.table$Adgroup[i],
Day == accomodate.table$Day[i])
# calculate the total amount of impressions
# create a column with the percentage that each keyword represents
current.data$PercImpressions = current.data$Impressions/sum(current.data$Impressions)
# 1 + Adrelevance + LP Experience + Expected CTR
current.data$CtgQualityScore = round(1 + as.numeric(current.data$Adrelevance) + as.numeric(current.data$Landingpageexperience) + as.numeric(current.data$Expectedclickthroughrate), 2)
# reorder columns to have our quality score and google's quality score next to each other
# current.data = current.data %>% select(1:8, CtgQualityScore, everything())
# print the quality scores values in the table to accomodate
accomodate.table$Impressions[i] = sum(current.data$Impressions)
accomodate.table$Qualityscore[i] = round(sum(as.numeric(current.data$CtgQualityScore) * current.data$PercImpressions), 2)
accomodate.table$Landingpageexperience[i] = round(sum(as.numeric(current.data$Landingpageexperience) * current.data$PercImpressions), 2)
accomodate.table$Expectedclickthroughrate[i] = round(sum(as.numeric(current.data$Expectedclickthroughrate) * current.data$PercImpressions), 2)
accomodate.table$Adrelevance[i] = round(sum(as.numeric(current.data$Adrelevance) * current.data$PercImpressions), 2)
}
# # change scale for landing page experience, expected CTR and ad relevance
# accomodate.table$Landingpageexperience = round(as.numeric(accomodate.table$Landingpageexperience)/3.5*10, digits = 2)
# accomodate.table$Expectedclickthroughrate = round(as.numeric(accomodate.table$Expectedclickthroughrate)/3.5*10, digits = 2)
# accomodate.table$Adrelevance = round(as.numeric(accomodate.table$Adrelevance)/2*10, digits = 2)
return(accomodate.table)
}
# 8) function that populated the table with quality score data at the campaign level-------
populate.table.campaigns = function(){
# length
lang = nrow(accomodate.table)
print("No. Iterations:")
print(lang)
# lang = 10000
for(i in 1:lang){
# test
# i = 1
print(i)
# get the data for one campaign and one day in particular
current.data = quality.score.data %>% filter(Account == accomodate.table$Account[i],
Campaign == accomodate.table$Campaign[i],
Day == accomodate.table$Day[i])
# calculate the total amount of impressions
# create a column with the percentage that each keyword represents
current.data$PercImpressions = current.data$Impressions/sum(current.data$Impressions)
# 1 + Adrelevance + LP Experience + Expected CTR
current.data$CtgQualityScore = round(1 + as.numeric(current.data$Adrelevance) + as.numeric(current.data$Landingpageexperience) + as.numeric(current.data$Expectedclickthroughrate), 2)
# print the qualiy scores values in the table to accomodate
accomodate.table$Impressions[i] = sum(current.data$Impressions)
accomodate.table$Qualityscore[i] = round(sum(as.numeric(current.data$CtgQualityScore) * current.data$PercImpressions), 2)
accomodate.table$Landingpageexperience[i] = round(sum(as.numeric(current.data$Landingpageexperience) * current.data$PercImpressions), 2)
accomodate.table$Expectedclickthroughrate[i] = round(sum(as.numeric(current.data$Expectedclickthroughrate) * current.data$PercImpressions), 2)
accomodate.table$Adrelevance[i] = round(sum(as.numeric(current.data$Adrelevance) * current.data$PercImpressions), 2)
}
# # change scale for landing page experience, expected CTR and ad relevance
# accomodate.table$Landingpageexperience = round(as.numeric(accomodate.table$Landingpageexperience)/3.5*10, digits = 2)
# accomodate.table$Expectedclickthroughrate = round(as.numeric(accomodate.table$Expectedclickthroughrate)/3.5*10, digits = 2)
# accomodate.table$Adrelevance = round(as.numeric(accomodate.table$Adrelevance)/2*10, digits = 2)
return(accomodate.table)
}
# 9) this function allows you to find the last date that we extracted data ----------------
find.last.date = function(query.data.set, query.table){
# download the current table
quality.table.reference = bq_table(project = project, dataset = query.data.set, table = query.table)
quality.score.current.table = bq_table_download(x = quality.table.reference)
dates = as.Date(unique(quality.score.current.table$Day))
last.date = sort(dates, decreasing = FALSE)[length(dates)]
return(last.date)
}
# 10) this functions appends data on an existing table on big query -----------------------
print_sequences = function(table.to.add, jump, q.project, q.data.set, q.table){
# table.to.add = test.2
# q.project = project
# q.data.set = data.set
# q.table = "Raw_Google_Ads_3"
starting.point = 1
sequences = seq(starting.point, nrow(table.to.add), jump)
last.sequence = sequences[length(sequences)]
counter = 0
for(i in sequences){ # determine how big the slice of data should be
# i = 100001 # testing
print(counter)
counter = counter + 1
# last sequence
if(i == last.sequence){
first = last.sequence
last = nrow(table.to.add)
current.batch = table.to.add[first:nrow(table.to.add),]
}else{
first = i
last = i+jump-1
current.batch = table.to.add[first:last,]
}
# get table
table.exists = bq_table(project = q.project, data = q.data.set, table = q.table)
if(bq_table_exists(table.exists)){ # if the table already exists, append
job = insert_upload_job(project = q.project, data = q.data.set,
table = q.table, write_disposition = "WRITE_APPEND",
values = current.batch, billing = q.project)
wait_for(job)
}else{ # if the table doesn't exist, create it and upload
bq_table_create(table.exists, current.batch)
bq_table_upload(table.exists, current.batch)
}
}
}
# 11) this functions gives you back all the campaign labels related to an account ---------
get.campaigns.labels = function(account.id, google_auth){
# what kind of data do you want in the query
get.metrics = c("CampaignName", "Date","Impressions", "Labels")
get.report = "CAMPAIGN_PERFORMANCE_REPORT"
# creaty query
body = statement(select = get.metrics, report = get.report, start = Sys.Date()-365, end = Sys.Date())
# get data from google ads
try({
campaign.data = getData(clientCustomerId = account.id, google_auth = google_auth, statement = body, transformation = TRUE, changeNames = TRUE)
}, silent = TRUE)
campaign.data = campaign.data %>% filter(Impressions > 0)
campaign.data$Impressions = NULL
return(campaign.data)
}
# 12) this functions creates the temporary table for campaign labels ----------------------
get.campaign.labels.table = function(){
# get the current account id
current.account.id = gs.accounts.table$`Account Id`[1]
# extract labels for one account id
all.campaign.labels = get.campaigns.labels(current.account.id, google_auth)
colnames(all.campaign.labels) = c("Campaign", "Date", "Campaign Labels")
# remove bad symbols such as backslashes
# all.campaign.labels = remove.bad.symbols()
all.campaign.labels$`Campaign Labels` = gsub(x = all.campaign.labels$`Campaign Labels`, pattern = '\"', replacement = "", fixed = TRUE)
all.campaign.labels$`Campaign Labels` = gsub(x = all.campaign.labels$`Campaign Labels`, pattern = '[', replacement = "", fixed = TRUE)
all.campaign.labels$`Campaign Labels` = gsub(x = all.campaign.labels$`Campaign Labels`, pattern = ']', replacement = "", fixed = TRUE)
# get all unique labels
all.campaigns.labels.vector = paste(all.campaign.labels$`Campaign Labels`, collapse = ",")
all.campaigns.labels.vector = str_split(string = all.campaigns.labels.vector, pattern = ",")[[1]]
all.campaigns.labels.vector = unique(all.campaigns.labels.vector)
# get unique dates
unique.dates = unique(quality.score.data$Day)
# create accomodate table for campaign labels
accomodate.table = expand.grid(all.campaigns.labels.vector, unique.dates)
# add additional columns to table
accomodate.table$Impressions = 0
accomodate.table$Qualityscore = 0
accomodate.table$Adrelevance = 0
accomodate.table$Landingpageexperience = 0
accomodate.table$Expectedclickthroughrate = 0
# add right columns
columns.to.add = c("Labels", "Date", "Impressions", "Qualityscore", "Adrelevance", "Landingpageexperience", "Expectedclickthroughrate")
colnames(accomodate.table) = columns.to.add
return(accomodate.table)
}
# 13) this functions removes bad symbols from campaign labels such as backslashes ---------
remove.bad.symbols = function(){
all.campaign.labels$`Campaign Labels` = gsub(x = all.campaign.labels$`Campaign Labels`, pattern = '\"', replacement = "", fixed = TRUE)
all.campaign.labels$`Campaign Labels` = gsub(x = all.campaign.labels$`Campaign Labels`, pattern = '[', replacement = "", fixed = TRUE)
all.campaign.labels$`Campaign Labels` = gsub(x = all.campaign.labels$`Campaign Labels`, pattern = ']', replacement = "", fixed = TRUE)
return(all.campaign.labels)
}
# 16) this function adds data to the quality score data table -----------------------------
add.labels.to.quality.score.data = function(){
quality.score.data$Labels = 0
# extract labels for one account id
all.campaign.labels = get.campaigns.labels(current.account.id, google_auth)
colnames(all.campaign.labels) = c("Campaign", "Date", "Campaign Labels")
all.campaign.labels = unique(all.campaign.labels[c("Campaign", "Campaign Labels")])
for(i in 1:nrow(all.campaign.labels)){
print(i)
# i = 1
current.campaign = all.campaign.labels$Campaign[i]
current.label = all.campaign.labels$`Campaign Labels`[i]
lines = str_detect(quality.score.data$Campaign, pattern = current.campaign)
quality.score.data$Labels[lines] = current.label
}
return(quality.score.data)
}
# 17) function that populated the table with quality score at the campaign label level -----
populate.table.labels = function(){
lang = nrow(accomodate.table)
print("No. Iterations:")
print(lang)
# lang = 20
for(i in 1:lang){
# test
# i = 5
print(i)
# get the data for one campaign label and one day in particular
current.data = quality.score.data %>% filter(Day == accomodate.table$Date[i],
grepl(accomodate.table$Labels[i], Labels))
# calculate the total amount of impressions
# create a column with the percentage that each keyword represents
current.data$PercImpressions = current.data$Impressions/sum(current.data$Impressions)
# 1 + Adrelevance + LP Experience + Expected CTR
current.data$CtgQualityScore = round(1 + as.numeric(current.data$Adrelevance) + as.numeric(current.data$Landingpageexperience) + as.numeric(current.data$Expectedclickthroughrate), 2)
# print the qualiy scores values in the table to accomodate
accomodate.table$Impressions[i] = sum(current.data$Impressions)
accomodate.table$Qualityscore[i] = round(sum(as.numeric(current.data$CtgQualityScore) * current.data$PercImpressions), 2)
accomodate.table$Landingpageexperience[i] = round(sum(as.numeric(current.data$Landingpageexperience) * current.data$PercImpressions), 2)
accomodate.table$Expectedclickthroughrate[i] = round(sum(as.numeric(current.data$Expectedclickthroughrate) * current.data$PercImpressions), 2)
accomodate.table$Adrelevance[i] = round(sum(as.numeric(current.data$Adrelevance) * current.data$PercImpressions), 2)
}
return(accomodate.table)
}
# *** INSTALL PACKAGES -----------------------------------------------------------------------
require('googlesheets')
require('tibble')
require('stringr')
require("stringi")
require('dplyr')
require('tidyr')
require('bigrquery')
require("tictoc")
google_auth_path = "/Users/arbenkqiku/Desktop/GitHub/Scripts/google_ads_auth.RData"
gs_auth(token = "/Users/arbenkqiku/Desktop/GitHub/Scripts/googlesheets_token_arben.rds")
bq_auth(path = "/Users/arbenkqiku/Desktop/GitHub/Scripts/BigQuery/key-scarab-261009-2d0fc84e7b17.json", email = "arben@comtogether.com") # local service account token
# big query
project = "key-scarab-261009"
data.set = "Quality_Score_MSC"
query.tables = c("Quality_Score_Campaign_Labels", "Quality_Score_Campaigns", "Quality_Score_Ad_Groups", "Quality_Score_Keywords", "Quality_Score_Raw")
# set dates
# google ads dates. Start date should be the next date to the last date available
# end date should be today - 1, as the today is not over and data will be incomplete.
# If you take up to yesterday, you can be sure that data is complete. It is important
# to run the general script once a week. If you run it with intervals of 1 day, data
# will be incomplete for the reason mentioned above
start.date = find.last.date(data.set, query.tables[4])+1 # last data available
# set dates
# google ads dates. Start date should be the next date to the last date available
# end date should be today - 1, as the today is not over and data will be incomplete.
# If you take up to yesterday, you can be sure that data is complete. It is important
# to run the general script once a week. If you run it with intervals of 1 day, data
# will be incomplete for the reason mentioned above
start.date = find.last.date(data.set, query.tables[4])+1 # last data available
end.date = Sys.Date()-1
# *** CODE ------------------------------------------------------------------------------------
# get accounts to loop through
gs.accounts = gs_title("MCC - Quality Score - 3")
# *** CODE ------------------------------------------------------------------------------------
# get accounts to loop through
gs.accounts = gs_title("MCC - Quality Score - 3")
# *** CODE ------------------------------------------------------------------------------------
# get accounts to loop through
gs.accounts = gs_title("MCC - Quality Score - 4")
# If you want the quality score data of all accounts
# gs.accounts.table = gs_read(ss = gs.accounts, ws = "Accounts")
# If you want the quality score data of MSC only
gs.accounts.table = gs_read(ss = gs.accounts, ws = "MSC")
# load google ads credentials
load.credentials(google_auth_path)
# 1) ----- ** get the raw data of all accounts ---------------------------------------
# create container
raw.accounts = as.data.frame(matrix(ncol = 11, nrow = 0))
colnames(raw.accounts) = c("Account", "Campaign", "Adgroup", "Keyword","Day", "Impressions", "HasQualityScore","Qualityscore",
"Adrelevance", "Landingpageexperience", "Expectedclickthroughrate")
#
# # # how much to loop through
lang = nrow(gs.accounts.table)
#
for(i in 1:lang){
# i = 39
print(i)
print(gs.accounts.table$`Account Name`[i])
# get the name of the current account id
current.account.id = gs.accounts.table$`Account Id`[i]
# get quality score data
quality.score.data = get.quality.score(current.account.id)
# proceed only if quality score table is not empty
if(nrow(quality.score.data) > 0){
# add account name to quality score
quality.score.data$Account = gs.accounts.table$`Account Name`[i]
# rearrange columns
quality.score.data = quality.score.data %>% select(Account, everything())
# bind together all clients data
raw.accounts = rbind(raw.accounts, quality.score.data)
}
}
end.date
# transfer info from container to other container
quality.score.data = raw.accounts
# transform quality score data into real numbers
quality.score.data = transform.in.numbers()
# remove rows that don't have a quality score
quality.score.data = quality.score.data %>% filter(HasQualityScore == "true")
# scale quality score data to 10
print_sequences(table.to.add = quality.score.data, jump = 100000, q.project = project, q.data.set = data.set, q.table = query.tables[5])
# # 2) ----- ** prepare table at the keyword level --------------------------------------
keywords.quality.score = populate.table.keywords(quality.score.data)
# print entire quality score data on a newly defined table
print_sequences(table.to.add = quality.score.data, jump = 100000, q.project = project, q.data.set = data.set, q.table = query.tables[4])
# 3) ----- ** prepare table at the ad group level --------------------------------------
# create table to accomodate data at the ad group level
accomodate.table = create.accomodate.table.adgroups()
tic()
ad.groups.table = populate.table.adgroups()
toc()
# print ad group quality score data on a newly defined table
print_sequences(table.to.add = ad.groups.table, jump = 100000, q.project = project, q.data.set = data.set, q.table = query.tables[3])
# # # 4) ----- ** prepare table at the campaign level --------------------------------------
# create table that will accomodate the data
accomodate.table = create.accomodate.table.campaigns()
# populate table with quality score data
campaigns.table = populate.table.campaigns()
# # print campaign quality score data on a newly defined table
print_sequences(table.to.add = campaigns.table, jump = 100000, q.project = project, q.data.set = data.set, q.table = query.tables[2])
# # # 5) ----- ** prep are table at the campaign label level ---------------------------------
# download quality score data [TEMP - TO REMOVE]
# reference = bq_table(project = project, data = data.set, table = query.tables[5])
# quality.score.data = bq_table_download(reference)
# create table that will accomodate the data
accomodate.table = get.campaign.labels.table()
# add campaign labels to quality score data
quality.score.data = add.labels.to.quality.score.data()
tic()
labels.table = populate.table.labels()
toc()
# print labels data to big query
print_sequences(table.to.add = labels.table, jump = 100000, q.project = project, q.data.set = data.set, q.table = query.tables[1])
